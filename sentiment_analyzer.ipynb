{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentiment analyser will predict whether an input sentence has positive or negative sentiment.\n",
    "\n",
    "Sentiment analyser is a classification task in machine learning. The classifier need to classify a sentence into positive sentiment (eg: I love coffee) or negative sentiment (eg: I hate golddiggers)\n",
    "\n",
    "Lets start coding...\n",
    "\n",
    "PREREQUESTIES:PYTHON BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported a classifier from sklearn package in the first line and CountVectorizer in the second line. \n",
    "\n",
    "It all make sense in a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [\n",
    "     ('I love this sandwich.', 'pos'), ('this is an amazing place!', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is my best work.', 'pos'),\n",
    "     (\"what an awesome view\", 'pos'),\n",
    "     ('I do not like this restaurant', 'neg'),\n",
    "     ('I am tired of this stuff.', 'neg'),\n",
    "     (\"I can't deal with this\", 'neg'),\n",
    "     ('he is my sworn enemy!', 'neg'),\n",
    "     ('my boss is horrible.', 'neg'),\n",
    "     (\"i hate you.\",'neg'),\n",
    "     (\"i love mangoes.\",'pos'),\n",
    "     (\"i am sad.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = [\n",
    "     ('the cake was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I am not feeling good today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Ebey is an amazing person.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need dataset for building such a classifier.\n",
    "\n",
    "Here we initialized a training dataset and testing dataset with input sentences and its corresponding sentiments ('pos' or 'neg') in tuples. \n",
    "\n",
    "We will use the train dataset for training the model and check whether the classifier is correct using the test dataset.\n",
    "\n",
    "Test dataset contain sentences the classfier didnt saw while training.\n",
    "\n",
    "So lets take each dataset and seperate into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "for data in train:\n",
    "    train_features.append(data[0])\n",
    "    train_labels.append(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seperately stored the features and labels for training into two list, train_features and train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features:  ['I love this sandwich.', 'this is an amazing place!', 'I feel very good about these beers.', 'this is my best work.', 'what an awesome view', 'I do not like this restaurant', 'I am tired of this stuff.', \"I can't deal with this\", 'he is my sworn enemy!', 'my boss is horrible.', 'i hate you.', 'i love mangoes.', 'i am sad.']\n"
     ]
    }
   ],
   "source": [
    "print(\"training features: \",train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels:  ['pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(\"training labels: \",train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing to test dataset !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_labels = []\n",
    "for data in test:\n",
    "    test_features.append(data[0])\n",
    "    test_labels.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing features:  ['the cake was good.', 'I do not enjoy my job', 'I am not feeling good today.', 'I feel amazing!', 'Ebey is an amazing person.', \"I can't believe I'm doing this.\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing features: \",test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing labels:  ['pos', 'neg', 'neg', 'pos', 'pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(\"testing labels: \",test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we have is in textual form. Machine leaarning algorithm will take only numerical data. \n",
    "\n",
    "So we convert this textual data into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that we will use CountVectorizer which will represent a sentence in vector based on frequency of words occured in the dataset.\n",
    "\n",
    "Lets see a small example first.\n",
    "\n",
    "Consider we have sentences like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balu love mougli', 'balu love bageera']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"balu love mougli\", \"balu love bageera\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the CountVectorizer() we can represent these sentences into vectors.\n",
    "\n",
    "First initilaizing the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorizer will initialize a vocabulary and create vectors based on the frequency of words occur in the dataset. For initializing the vocabulary and vectorize using that vocabulary we use the function fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = count_vect.fit_transform([\"balu love mougli\",\"balu love bageera\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the vectorizer did is it created a vocabulary with number of elements equal to the number of individual words in the above dataset in alphabetic order. \n",
    "\n",
    "That is 'bageera', 'balu', 'love' and 'mougli'.\n",
    "\n",
    "So as you can see the vector for a sentence contain four elements, each represents one word in the vocabulary. A sentence can be represented with the number of times the word occured in the sentence.\n",
    "\n",
    "For example,\n",
    "\n",
    "\"balu love mougli\" --> [0 1 1 1]\n",
    "\n",
    "(First word in the vocabulary, 'bageera' is not present in the sentence so first element is zero. All other words in vocabulary are present once, so the elements in their postions are made one. If some words occur twice in a sentence then corresponding element is made two and so on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say we have a new sentence, we have to convert it to vector based on the vocabulary we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balu love pikachu']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"balu love pikachu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use transform function in CountVectorizer for transforming the new input to vector based on the vocabulary we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = count_vect.transform([\"balu love pikachu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See we use the same object, count_vect to which we initialized the vocabulary. So calling transform() will vectorize the new input using that vocabulary.\n",
    "\n",
    "Lets see the output !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the output yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets vectorize our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = count_vect.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0]\n",
      " [1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  1 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert x_train to array for feeding it to the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the features in numerical format, now we need the labels also. One conventional practice is to label using 0,1,2... N for N labels.\n",
    "\n",
    "Here we have 2 labels, so lets represent 'pos' as 0 and 'neg' ad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for i in train_labels:\n",
    "    if i == 'pos':\n",
    "        y_train.append(0)\n",
    "    elif i == 'neg':\n",
    "        y_train.append(1)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done.Lets build the classifier now !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn a classifier has two functions, fit and predict.\n",
    "\n",
    "Function fit() will train the model using the dataset and after training we can use predict() for predicting the label giving a new input feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... Lets test the classifier using test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = count_vect.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test features are transformed to vectors using the training dataset vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the sentiments of test dataset ! If the predicted label is 0 that means corresponding sentence has positive sentiment, if 1 then its negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  the cake was good.\n",
      "sentiment:  positive\n",
      "input:  I do not enjoy my job\n",
      "sentiment:  negative\n",
      "input:  I am not feeling good today.\n",
      "sentiment:  negative\n",
      "input:  I feel amazing!\n",
      "sentiment:  positive\n",
      "input:  Ebey is an amazing person.\n",
      "sentiment:  positive\n",
      "input:  I can't believe I'm doing this.\n",
      "sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(test_features):\n",
    "    print(\"input: \",data)\n",
    "    if k[i] == 0:\n",
    "        print(\"sentiment: \",\"positive\")\n",
    "    elif k[i] == 1:\n",
    "        print(\"sentiment: \",\"negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
